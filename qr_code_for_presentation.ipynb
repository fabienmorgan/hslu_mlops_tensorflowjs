{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b379fdab2781422aa2114abd31d7ccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_image\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m controlnet \u001b[39m=\u001b[39m ControlNetModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mDionTimmer/controlnet_qrcode-control_v1p_sd15\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                              torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionControlNetImg2ImgPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrunwayml/stable-diffusion-v1-5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     controlnet\u001b[39m=\u001b[39;49mcontrolnet,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     safety_checker\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pipe\u001b[39m.\u001b[39menable_xformers_memory_efficient_attention()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabienmorgan/Desktop/Ausbildung/Studium/MLOPS/Project3/hslu_mlops_tensorflowjs/qr_code_for_presentation.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m pipe\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m DDIMScheduler\u001b[39m.\u001b[39mfrom_config(pipe\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops_project3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1265\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m passed_class_obj[name]\n\u001b[1;32m   1263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1264\u001b[0m     \u001b[39m# load sub model\u001b[39;00m\n\u001b[0;32m-> 1265\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_sub_model(\n\u001b[1;32m   1266\u001b[0m         library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m   1267\u001b[0m         class_name\u001b[39m=\u001b[39;49mclass_name,\n\u001b[1;32m   1268\u001b[0m         importable_classes\u001b[39m=\u001b[39;49mimportable_classes,\n\u001b[1;32m   1269\u001b[0m         pipelines\u001b[39m=\u001b[39;49mpipelines,\n\u001b[1;32m   1270\u001b[0m         is_pipeline_module\u001b[39m=\u001b[39;49mis_pipeline_module,\n\u001b[1;32m   1271\u001b[0m         pipeline_class\u001b[39m=\u001b[39;49mpipeline_class,\n\u001b[1;32m   1272\u001b[0m         torch_dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   1273\u001b[0m         provider\u001b[39m=\u001b[39;49mprovider,\n\u001b[1;32m   1274\u001b[0m         sess_options\u001b[39m=\u001b[39;49msess_options,\n\u001b[1;32m   1275\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   1276\u001b[0m         max_memory\u001b[39m=\u001b[39;49mmax_memory,\n\u001b[1;32m   1277\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   1278\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   1279\u001b[0m         model_variants\u001b[39m=\u001b[39;49mmodel_variants,\n\u001b[1;32m   1280\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1281\u001b[0m         from_flax\u001b[39m=\u001b[39;49mfrom_flax,\n\u001b[1;32m   1282\u001b[0m         variant\u001b[39m=\u001b[39;49mvariant,\n\u001b[1;32m   1283\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   1284\u001b[0m         cached_folder\u001b[39m=\u001b[39;49mcached_folder,\n\u001b[1;32m   1285\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1287\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1288\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m as \u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m from `\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m` subfolder of \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[1;32m   1291\u001b[0m init_kwargs[name] \u001b[39m=\u001b[39m loaded_sub_model  \u001b[39m# UNet(...), # DiffusionSchedule(...)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops_project3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:520\u001b[0m, in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, revision)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m# check if the module is in a subdirectory\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cached_folder, name)):\n\u001b[0;32m--> 520\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(cached_folder, name), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mloading_kwargs)\n\u001b[1;32m    521\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     \u001b[39m# else load from the root directory\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(cached_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mloading_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops_project3/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:812\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_keys) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    806\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot load \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m because the following keys are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m missing: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(missing_keys)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Please make sure to pass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `low_cpu_mem_usage=False` and `device_map=None` if you want to randomly initialize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m those weights or else make sure your checkpoint file is correct.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m     )\n\u001b[0;32m--> 812\u001b[0m unexpected_keys \u001b[39m=\u001b[39m load_model_dict_into_meta(\n\u001b[1;32m    813\u001b[0m     model,\n\u001b[1;32m    814\u001b[0m     state_dict,\n\u001b[1;32m    815\u001b[0m     device\u001b[39m=\u001b[39;49mparam_device,\n\u001b[1;32m    816\u001b[0m     dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m    817\u001b[0m     model_name_or_path\u001b[39m=\u001b[39;49mpretrained_model_name_or_path,\n\u001b[1;32m    818\u001b[0m )\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_keys_to_ignore_on_load_unexpected \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[39mfor\u001b[39;00m pat \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_keys_to_ignore_on_load_unexpected:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops_project3/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:160\u001b[0m, in \u001b[0;36mload_model_dict_into_meta\u001b[0;34m(model, state_dict, device, dtype, model_name_or_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    156\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot load \u001b[39m\u001b[39m{\u001b[39;00mmodel_name_or_path_str\u001b[39m}\u001b[39;00m\u001b[39mbecause \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m}\u001b[39;00m\u001b[39m expected shape \u001b[39m\u001b[39m{\u001b[39;00mempty_state_dict[param_name]\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m. If you want to instead overwrite randomly initialized weights, please make sure to pass both `low_cpu_mem_usage=False` and `ignore_mismatched_sizes=True`. For more information, see also: https://github.com/huggingface/diffusers/issues/1619#issuecomment-1345604389 as an example.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m accepts_dtype:\n\u001b[0;32m--> 160\u001b[0m     set_module_tensor_to_device(model, param_name, device, value\u001b[39m=\u001b[39;49mparam, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     set_module_tensor_to_device(model, param_name, device, value\u001b[39m=\u001b[39mparam)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops_project3/lib/python3.11/site-packages/accelerate/utils/modeling.py:293\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    291\u001b[0m         value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mto(old_value\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    292\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m(value\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mstartswith((\u001b[39m\"\u001b[39m\u001b[39mtorch.uint\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtorch.int\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtorch.bool\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m--> 293\u001b[0m         value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mto(dtype)\n\u001b[1;32m    295\u001b[0m param \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_parameters[tensor_name] \u001b[39mif\u001b[39;00m tensor_name \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_parameters \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    296\u001b[0m param_cls \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(param)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, DDIMScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"DionTimmer/controlnet_qrcode-control_v1p_sd15\",\n",
    "                                             torch_dtype=torch.float16)\n",
    "\n",
    "pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "def resize_for_condition_image(input_image: Image, resolution: int):\n",
    "    input_image = input_image.convert(\"RGB\")\n",
    "    W, H = input_image.size\n",
    "    k = float(resolution) / min(H, W)\n",
    "    H *= k\n",
    "    W *= k\n",
    "    H = int(round(H / 64.0)) * 64\n",
    "    W = int(round(W / 64.0)) * 64\n",
    "    img = input_image.resize((W, H), resample=Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "\n",
    "# play with guidance_scale, controlnet_conditioning_scale and strength to make a valid QR Code Image\n",
    "\n",
    "# qr code image\n",
    "source_image = load_image(\"qrcode.png\")\n",
    "# initial image, anything\n",
    "init_image = load_image(\"https://previews.123rf.com/images/chuyu/chuyu1212/chuyu121200092/17048157-blue-circuit-board-background-of-computer-motherboard.jpg\")\n",
    "condition_image = resize_for_condition_image(source_image, 768)\n",
    "init_image = resize_for_condition_image(init_image, 768)\n",
    "generator = torch.manual_seed(123121231)\n",
    "image = pipe(prompt=\"beatiful, neon, 4k, cyberpunk\",\n",
    "             negative_prompt=\"ugly, disfigured, low quality, blurry, nsfw\", \n",
    "             image=init_image,\n",
    "             control_image=condition_image,\n",
    "             width=768,\n",
    "             height=768,\n",
    "             guidance_scale=30,\n",
    "             controlnet_conditioning_scale=3.0,\n",
    "             generator=generator,\n",
    "             strength=0.5, \n",
    "             num_inference_steps=150,\n",
    "            )\n",
    "\n",
    "image.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.images[0].save(\"ai_qrcode.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_project3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
